# -*- coding: utf-8 -*-
"""bmi_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfclbWOlfeiAakp2YDU3YS6_0f1YH6ee
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('bmi.csv')

print(df.info())

df.head()

print(df['BmiClass'].value_counts())

from sklearn.preprocessing import StandardScaler, LabelEncoder
label_encoder = LabelEncoder()
df['BmiClass_encoded'] = label_encoder.fit_transform(df['BmiClass'])
class_names = label_encoder.classes_

X = df[['Age', 'Height', 'Weight']]
y = df['BmiClass_encoded']

X

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

X_train

X_test

y_train

y_test

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train_scaled, y_train)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
y_pred = clf.predict(X_test_scaled)

# Accuracy and detailed report
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=class_names))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, fmt="d", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

import joblib

joblib.dump(clf, "bmi_classifier.pkl")
joblib.dump(scaler, "bmi_scaler.pkl")
joblib.dump(label_encoder, "bmi_label_encoder.pkl")

# Example new input
new_input = pd.DataFrame([[30, 1.65, 70]], columns=["Age", "Height", "Weight"])

# Preprocess and predict
new_input_scaled = scaler.transform(new_input)
predicted_class = clf.predict(new_input_scaled)
predicted_label = label_encoder.inverse_transform(predicted_class)

print("Predicted BMI Class:", predicted_label[0])

# Example new input
new_input = pd.DataFrame([[30, 1.65, 70]], columns=["Age", "Height", "Weight"])

# Calculate BMI
new_input['BMI'] = new_input['Weight'] / (new_input['Height']**2)

# Preprocess and predict
new_input_scaled = scaler.transform(new_input[['Age', 'Height', 'Weight']])
predicted_class = clf.predict(new_input_scaled)
predicted_label = label_encoder.inverse_transform(predicted_class)

print("BMI:", new_input['BMI'].iloc[0])
print("Predicted BMI Class:", predicted_label[0])

import time

start = time.time()
clf.fit(X_train_scaled, y_train) # Changed 'model' to 'clf'
end = time.time()

print(f"Training time: {end - start:.4f} seconds")

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": SVC(random_state=42),
    "KNN": KNeighborsClassifier()
}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    print(f"{name}: {acc:.2%}")

print("Confusion Matrix:\n", cm)

if hasattr(clf, 'feature_importances_'):
  importances = clf.feature_importances_
  feature_names = X.columns
  feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
  feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)

  plt.figure(figsize=(10, 6))
  sns.barplot(x='importance', y='feature', data=feature_importance_df)
  plt.title('Random Forest Feature Importance')
  plt.show()

model_names = list(models.keys())
accuracies = [accuracy_score(y_test, models[name].predict(X_test_scaled)) for name in model_names]

plt.figure(figsize=(10, 6))
sns.barplot(x=model_names, y=accuracies)
plt.ylabel('Accuracy')
plt.title('Model Comparison based on Accuracy')
plt.ylim(0, 1) # Set y-axis limit from 0 to 1 for accuracy values
plt.show()

